# 一、分布式锁

在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。

阻塞锁通常使用互斥量来实现：

- 互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态；
- 互斥量为 1 表示未锁定状态。

1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。

## 1、数据库锁

### 基于MySQL锁表

该实现方式完全依靠**数据库唯一索引**来实现，获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否处于锁定状态。

存在以下几个问题：

- 锁没有失效时间，解锁失败的话其它进程无法再获得该锁；
- 只能是非阻塞锁，插入失败直接就报错了，无法重试；
- 不可重入，已经获得锁的进程也必须重新获取锁。

### 乐观锁增加版本号

根据版本号来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。

## 2、缓存锁

这里我们主要介绍几种基于**redis**实现的分布式锁：

### **基于setnx、expire两个命令来实现**

基于**setnx（set if not exist**）的特点，当缓存里key不存在时，才会去set，否则直接返回false。如果返回true则获取到锁，否则获取锁失败，**为了防止死锁，我们再用expire命令对这个key设置一个超时时间来避免**。但是这里看似完美，实则有缺陷，当我们setnx成功后，线程发生异常中断，expire还没来的及设置，那么就会产生死锁。

解决上述问题有两种方案：

- 采用redis2.6.12版本以后的**set**，它提供了一系列选项：

  - EX seconds – 设置键key的过期时间，单位时秒
  - PX milliseconds – 设置键key的过期时间，单位时毫秒
  - NX – 只有键key不存在的时候才会设置key的值
  - XX – 只有键key存在的时候才会设置key的值

- 采用**setnx()，get()，getset()**实现

  - 线程A setnx，值为超时的时间戳(t1)，如果返回true，获得锁。

  - 线程B用get 命令获取t1，与当前时间戳比较，判断是否超时，没超时false，如果已超时执行步骤3

  - 计算新的超时时间t2，使用getset命令返回t3(这个值可能其他线程已经修改过)，如果t1==t3,获得锁,如果t1!=t3说明锁被其他线程获取了

  - 获取锁后，处理完业务逻辑，再去判断锁是否超时，如果没超时删除锁，如果已超时，不用处理（防止删除其他线程的锁）

### RedLock算法

redlock算法是redis作者推荐的一种分布式锁实现方式，算法的内容如下：

​	(1) 获取当前时间；

​	(2) 尝试从**5个**相互独立redis客户端获取锁；

​	(3) 计算获取所有锁消耗的时间，当且仅当客户端从**多数节点**获取锁，并且获取锁的时间小于锁的有效时间，认为获得锁；

​	(4) 重新计算有效期时间，原有效时间减去获取锁消耗的时间；

​	(5) 删除所有实例的锁

redlock算法相对于单节点redis锁可靠性要更高，但是实现起来条件也较为苛刻。

(1) 必须部署5个节点才能让Redlock的可靠性更强。

(2) 需要请求5个节点才能获取到锁，通过Future的方式，先并发向5个节点请求，再一起获得响应结果，能缩短响应时间，不过还是比单节点redis锁要耗费更多时间。

### 3、zookeeper分布式锁

首先我们来了解一下zookeeper的特性，看看它为什么适合做分布式锁，

zookeeper是一个为分布式应用提供**一致性服务的软件**，它内部是一个分层的文件系统目录树结构，规定统一个目录下只能有一个唯一文件名。

数据模型：

- **永久节点**：节点创建后，不会因为会话失效而消失
- **临时节点**：与永久节点相反，如果客户端连接失效，则立即删除节点
- **顺序节点**：与上述两个节点特性类似，如果指定创建这类节点时，zk会自动在节点名后加一个数字后缀，并且是有序的。

**监视器**（watcher）：

- 当创建一个节点时，可以注册一个该节点的监视器，当节点状态发生改变时，watch被触发时，ZooKeeper将会向客户端发送且仅发送一条通知，因为watch只能被触发一次。

根据zookeeper的这些特性，我们来看看如何利用这些特性来实现分布式锁：

1. 创建一个锁目录lock

2. 希望获得锁的线程A就在lock目录下，创建临时顺序节点

3. 获取锁目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁

4. 线程B获取所有节点，判断自己不是最小节点，设置监听(watcher)比自己次小的节点（只关注比自己次小的节点是为了防止发生“羊群效应”）

5. 线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是最小的节点，获得锁。

### 4、比较

数据库锁：

- 优点：直接使用数据库，使用简单。
- 缺点：分布式系统大多数瓶颈都在数据库，使用数据库锁会增加数据库负担。

缓存锁：

- 优点：性能高，实现起来较为方便，在允许偶发的锁失效情况，不影响系统正常使用，建议采用缓存锁。
- 缺点：通过锁超时机制不是十分可靠，当线程获得锁后，处理时间过长导致锁超时，就失效了锁的作用。

zookeeper锁：

- 优点：不依靠超时时间释放锁；可靠性高；系统要求高可靠性时，建议采用zookeeper锁。
- 缺点：性能比不上缓存锁，因为要频繁的创建节点删除节点。

---

# 二、分布式事务

指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。

例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。

分布式锁和分布式事务区别：

- 锁问题的关键在于进程操作的互斥关系，例如多个进程同时修改账户的余额，如果没有互斥关系则会导致该账户的余额不正确。
- 而事务问题的关键则在于事务涉及的一系列操作需要满足 ACID 特性，例如要满足原子性操作则需要这些操作要么都执行，要么都不执行。

## 2PC 两阶段提交

两阶段提交（Two-phase Commit，2PC），通过引入**协调者（Coordinator）**来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。

- 过程：

  - **准备阶段**：

    协调者询问参与者事务是否执行成功，参与者发回事务执行结果。询问可以看成一种投票，需要参与者都同意才能执行。

  - **提交阶段**：

    如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。

    需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。

- 问题：

  - **同步阻塞**：

    所有事务参与者在等待其它参与者响应的时候都处于同步阻塞等待状态，无法进行其它操作。

  - **单点问题**：

    协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在提交阶段发生故障，所有参与者会一直同步阻塞等待，无法完成其它操作。

  - **数据不一致**：

    在提交阶段，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。

  - **太过保守**：

    任意一个节点失败就会导致整个事务失败，没有完善的容错机制。

## 本地消息表

本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。

1. 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。
2. 之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。
3. 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。

![](https://camo.githubusercontent.com/a0b613a1f60db10d1ff1b24810c2ecea4a92d200/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34373633323964342d653265662d346637622d386163392d6135326136663738343630302e706e67)

---

# 三、CAP理论

分布式系统不可能同时满足**一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance）**，**最多只能同时满足其中两项**。

## 一致性

一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。

对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。

## 可用性

可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。

在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。

## 分区容忍性

网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。

在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。

## 权衡

在分布式系统中，**分区容忍性必不可少**，因为需要总是假设网络是不可靠的。因此，CAP 理论实际上是要在可用性和一致性之间做权衡。

可用性和一致性往往是冲突的，很难使它们同时满足。在多个节点之间进行数据同步时，

- **为了保证一致性（CP），不能访问未同步完成的节点，也就失去了部分可用性；**
- **为了保证可用性（AP），允许读取所有节点的数据，但是数据可能不一致。**

---

# 四、BASE理论

BASE 是**基本可用（Basically Available）**、**软状态（Soft State）**和**最终一致性（Eventually Consistent）**三个短语的缩写。

BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到**最终一致性**。

## 基本可用

指分布式系统在出现故障的时候，**保证核心可用，允许损失部分可用性**。

例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。

## 软状态

指允许系统中的**数据存在中间状态**，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。

## 最终一致性

最终一致性强调的是系统中所有的数据副本，**在经过一段时间的同步后，最终能达到一致的状态**。

**ACID 要求强一致性，通常运用在传统的数据库系统上**。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在**大型分布式系统中**。

在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。

---

# 五、Paxos算法 -- 共识算法

用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。

主要有三类节点：

- **提议者**（Proposer）：提议一个值；
- **接受者**（Acceptor）：对每个提议进行投票；
- **告知者**（Learner）：被告知投票的结果，不参与投票过程。

![](https://camo.githubusercontent.com/63fb9ce3f8fe44eafe59559b3745528c13d907f7/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62393838383737632d306630612d343539332d393136642d6465323038313332303632382e6a7067)

## 过程：

规定一个提议包含两个字段：**[n, v]，其中 n 为序号（具有唯一性），v 为提议值**。

- **Prepare阶段：**

  每个 Proposer 都会向所有 Acceptor 发送 Prepare 请求；

  当 Acceptor 接收到 Prepare 请求，包含的提议为 [n1, v1]，并且之前还未接收过 Prepare 请求，那么发送一个 Prepare 响应，设置当前接收到的提议为 [n1, v1]，并且保证以后**不会再接受序号小于 n1 的提议**。

  如果 Acceptor 接收到一个 Prepare 请求，包含的提议为 [n2, v2]，并且之前已经接收过提议 [n1, v1]。如果 n1 > n2，那么就丢弃该提议请求；否则，发送 Prepare 响应，该 Prepare 响应包含之前已经接收过的提议 [n1, v1]，设置当前接收到的提议为 [n2, v2]，并且保证以后不会再接受序号小于 n2 的提议。

- **Accept阶段：**

  当一个 Proposer 接收到超过一半 Acceptor 的 Prepare 响应时，就可以发送 Accept 请求。

- **Learn阶段：**

  Acceptor 接收到 Accept 请求时，如果序号大于等于该 Acceptor 承诺的最小序号，那么就发送 Learn 提议给所有的 Learner。当 Learner 发现有大多数的 Acceptor 接收了某个提议，那么该提议的提议值就被 Paxos 选择出来。

## 约束条件：

### 1. 正确性

指只有一个提议值会生效。

因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。

### 2. 可终止性

指最后总会有一个提议生效。

Paxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。

---

# 六、Raft算法 -- 共识算法

Raft 也是**分布式一致性协议**，主要是用来**竞选主节点**。

## 单个Candidate竞选

有三种节点：**Follower、Candidate 和 Leader**。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个**随机的竞选超时时间**，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。

- 分布式系统的最初阶段，此时只有 Follower 没有 Leader。Node A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。
- 此时 Node A 发送投票请求给其它所有节点。
- 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。
- 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。

## 多个Candidate竞选

- 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票。 Node B 和 Node D 都获得两票，需要重新开始投票。
- 由于每个节点设置的随机竞选超时时间不同，因此下一次再次出现多个 Candidate 并获得同样票数的概率很低。

## 数据同步

- 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。
- Leader 会把修改复制到所有 Follower。
- Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。
- 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。